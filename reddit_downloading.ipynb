{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit\n",
    "\n",
    "Registering \n",
    "https://www.reddit.com/wiki/api/\n",
    "\n",
    "The api [page](https://www.reddit.com/dev/api/) on reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRAW\n",
    "\n",
    "[PRAW](https://praw.readthedocs.io/en/stable/) is a python library for downloading directly using Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "reddit = praw.Reddit(\n",
    "     client_id='2i5iNuPArbl7hQ',\n",
    "     client_secret='BH2xbjejLWhWzby7BopJ2gbhs7Kwxw',\n",
    "     user_agent='bsherin'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"magictcg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for submission in subreddit.hot(limit=10):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions = list(subreddit.hot(limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions = list(submissions)\n",
    "dir(submissions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pushshift\n",
    "\n",
    "https://www.reddit.com/r/pushshift/\n",
    "https://www.reddit.com/user/Pushshift-Support\n",
    "\n",
    "This is the big historical database. But we can't access it at the moment.\n",
    "\n",
    "Some useful links\n",
    "https://www.reddit.com/r/pushshift/comments/14ei799/pushshift_live_again_and_how_moderators_can/\n",
    "https://www.reddit.com/r/pushshift/comments/1546qyj/bug_fix_update_exact_match_fix/jsnpzey/?context=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Look at [pushshift](https://www.reddit.com/r/pushshift/comments/bcxguf/new_to_pushshift_read_this_faq/)\n",
    "\n",
    "Search interface is [here](https://redditsearch.io)\n",
    "\n",
    "pushshift [api](https://github.com/pushshift/api) (A good place to look)\n",
    "\n",
    "### PMAW\n",
    "There's a python [library](https://github.com/mattpodolak/pmaw) for accessing it. This seems to get a <span style=\"color:orange\">larger number of elements</span> and is easy. It can use <span style=\"color:orange\">PRAW to enrich results</span>  with current information. I try it below. PRAW is [here](https://praw.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# various definitions\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "def epoch(year, month=1, day=1, hour=0, minute=0):\n",
    "    return int(datetime(year, month, day, hour, minute).timestamp())\n",
    "\n",
    "useful_fields = [\n",
    "    \"author\", \"body\", \"created_utc\",\n",
    "    \"_replies\", \"ups\", \n",
    "    \"likes\", \"score\", \"downs\",\n",
    "    \"all_awardings\", \"awarders\", \"total_awards_received\",\n",
    "    \"is_submitter\", \"subreddit\",\n",
    "    \"id\", \"parent_id\"\n",
    "]\n",
    "suseful_fields = [\n",
    "    \"author\", \"body\", \"created_utc\", \n",
    "    \"score\",\n",
    "    \"is_submitter\", \"subreddit\",\n",
    "    \"id\", \"parent_id\"\n",
    "]\n",
    "def reduce_comment(comment):\n",
    "    res = {}\n",
    "    for ufield in useful_fields:\n",
    "        if ufield in comment:\n",
    "            res[ufield] = comment[ufield]\n",
    "        else:\n",
    "            res[ufield] = \"None\"\n",
    "    return res\n",
    "\n",
    "from datetime import datetime\n",
    "def convert_epoch(epoch):\n",
    "    dt = datetime.fromtimestamp(epoch)\n",
    "    return dt\n",
    "\n",
    "def get_earliest_epoch(clist):\n",
    "    df = pd.DataFrame(clist)\n",
    "    df = df.astype({\"created_utc\": \"int64\"})\n",
    "    dfs = df.sort_values(by=\"created_utc\")\n",
    "    before = dfs.iloc[0][\"created_utc\"]\n",
    "    return before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_praw = False\n",
    "subreddit = \"magicTCG\"\n",
    "chunksize = 250\n",
    "runspan = 2000\n",
    "before = epoch(2021, 2)\n",
    "final_after = epoch(2021)\n",
    "continue_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pmaw import PushshiftAPI\n",
    "if use_praw:\n",
    "    import praw\n",
    "    reddit = praw.Reddit(\n",
    "     client_id='2i5iNuPArbl7hQ',\n",
    "     client_secret='BH2xbjejLWhWzby7BopJ2gbhs7Kwxw',\n",
    "     user_agent=f'python: PMAW request enrichment (by u/bsherin)'\n",
    "    )\n",
    "    api = PushshiftAPI(praw=reddit, num_workers=1)\n",
    "else:\n",
    "    api = PushshiftAPI(num_workers=1)\n",
    "if continue_run:\n",
    "    before = get_earliest_epoch(all_results)\n",
    "    starting_count = len(all_results)\n",
    "else:\n",
    "    all_results = []\n",
    "    starting_count = 0\n",
    "while True:\n",
    "    comments = api.search_comments(subreddit=subreddit, limit=chunksize, after=final_after, before=before)\n",
    "    rcl = [reduce_comment(cmt) for cmt in comments]\n",
    "    if len(rcl) == 0:\n",
    "        break\n",
    "    all_results += rcl\n",
    "    before = get_earliest_epoch(rcl)\n",
    "    print(convert_epoch(before))\n",
    "    if runspan is not None and (len(allresults) - starting_count) >= runspan:\n",
    "        print(\"reached runspan\")\n",
    "        break\n",
    "    if before <= final_after:\n",
    "        print(\"Reached final_after\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rcl = [reduce_comment(cmt) for cmt in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comments = api.search_comments(subreddit=\"science\", limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comment_list = [comment for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pmaw import PushshiftAPI\n",
    "\n",
    "api = PushshiftAPI()\n",
    "comments = api.search_comments(subreddit=\"science\", limit=1000)\n",
    "comment_list = [comment for comment in comments]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
