{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39cd825b-eb27-4524-af97-ced8ca7c1be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "import zstandard\n",
    "from datetime import datetime\n",
    "import logging.handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b72fa15c-8c35-42de-ac48-3f5a632247c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put the path to the input file\n",
    "input_file = r\"C:\\Users\\HP\\prj\\bsherin\\learning-trajectories\\reddit\\a2c-data\\ApplyingToCollege_submissions.zst\"\n",
    "# put the name or path to the output file. The file extension from below will be added automatically\n",
    "output_file = r\"C:\\Users\\HP\\prj\\bsherin\\learning-trajectories\\reddit-outputs\\all-a2c-output-text-users-dates-csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67d41f0-eccc-4705-b212-12e36285825b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_file = \"/Users/brucesherin/PycharmProjects/learning-trajectories/subreddits/ApplyingToCollege_submissions.zst\"\n",
    "output_file = \"/Users/brucesherin/PycharmProjects/learning-trajectories/subreddits/all-a2c-output-text-users-dates-csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3789b7e-1635-44be-9280-6ff845152f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the format to output in, pick from the following options\n",
    "#   zst: same as the input, a zstandard compressed ndjson file. Can be read by the other scripts in the repo\n",
    "#   txt: an ndjson file, which is a text file with a separate json object on each line. Can be opened by any text editor\n",
    "#   csv: a comma separated value file. Can be opened by a text editor or excel\n",
    "# WARNING READ THIS: if you use txt or csv output on a large input file without filtering \n",
    "# out most of the rows, the resulting file will be extremely large. \n",
    "# Usually about 7 times as large as the compressed input file\n",
    "output_format = \"txt\"\n",
    "# override the above format and output only this field into a text file, one per line. Useful if you want to make a list of authors or ids. See the examples below\n",
    "# any field that's in the dump is supported, but useful ones are\n",
    "#   author: the username of the author\n",
    "#   id: the id of the submission or comment\n",
    "#   link_id: only for comments, the fullname of the submission the comment is associated with\n",
    "#   parent_id: only for comments, the fullname of the parent of the comment. Either another comment or the submission if it's top level\n",
    "desired_field1 = \"title\"\n",
    "desired_field2 = \"selftext\"\n",
    "desired_field3 = \"author\"\n",
    "desired_field4 = \"created_utc\"\n",
    "# the fields in the file are different depending on whether it has comments or submissions. If we're writing a csv, we need to know which fields to write.\n",
    "# The filename from the torrent has which type it is, but you'll need to change this if you removed that from the filename\n",
    "is_submission = \"submission\" in input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "496e6f04-46ec-4725-8a2a-ab1ec78c8a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only output items between these two dates\n",
    "from_date = datetime.strptime(\"2021-01-01\", \"%Y-%m-%d\")\n",
    "to_date = datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4edeb244-9e6d-47d0-99e0-22ca6e7f4004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = \"title\"\n",
    "values = []\n",
    "# if you have a long list of values, you can put them in a file and put the filename here. If set this overrides the value list above\n",
    "# if this list is very large, it could greatly slow down the process\n",
    "values_file = None\n",
    "exact_match = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b93f66-f8ca-42be-b1f8-dd6d6841b32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sets up logging to the console as well as a file\n",
    "log = logging.getLogger(\"bot\")\n",
    "log.setLevel(logging.INFO)\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s: %(message)s')\n",
    "log_str_handler = logging.StreamHandler()\n",
    "log_str_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_str_handler)\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")\n",
    "log_file_handler = logging.handlers.RotatingFileHandler(os.path.join(\"logs\", \"bot.log\"), maxBytes=1024*1024*16, backupCount=5)\n",
    "log_file_handler.setFormatter(log_formatter)\n",
    "log.addHandler(log_file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cccfbb9a-452c-42e7-9625-d3f5cc81110f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_line_zst(handle, line):\n",
    "    handle.write(line.encode('utf-8'))\n",
    "    handle.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbed7f8b-dff7-48a6-b362-3970980e3bee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_line_json(handle, obj):\n",
    "    handle.write(json.dumps(obj))\n",
    "    handle.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ad7404-fe6e-4fca-af13-4fb28b81710c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_line_single(handle, obj, field):\n",
    "    if field in obj:\n",
    "        handle.write(str(obj[field]))\n",
    "    else:\n",
    "        log.info(f\"{field} not in object {obj['id']}\")\n",
    "    handle.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe2c3a0c-6b43-48ce-8593-f48c6d60bc63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_line_csv(writer, obj, is_submission):\n",
    "    output_list = []\n",
    "    output_list.append(str(obj['score']))\n",
    "    output_list.append(datetime.fromtimestamp(float(obj['created_utc'])).strftime(\"%Y-%m-%d\"))\n",
    "    if is_submission:\n",
    "        output_list.append(obj['title'])\n",
    "    output_list.append(f\"u/{obj['author']}\")\n",
    "    output_list.append(f\"https://www.reddit.com{obj['permalink']}\")\n",
    "    if is_submission:\n",
    "        if obj['is_self']:\n",
    "            if 'selftext' in obj:\n",
    "                output_list.append(obj['selftext'])\n",
    "            else:\n",
    "                output_list.append(\"\")\n",
    "        else:\n",
    "            output_list.append(obj['url'])\n",
    "    else:\n",
    "        output_list.append(obj['body'])\n",
    "    writer.writerow(output_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80965d04-11c9-4e78-bbf8-6f89231792a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_decode(reader, chunk_size, max_window_size, previous_chunk=None, bytes_read=0):\n",
    "    chunk = reader.read(chunk_size)\n",
    "    bytes_read += chunk_size\n",
    "    if previous_chunk is not None:\n",
    "        chunk = previous_chunk + chunk\n",
    "    try:\n",
    "        return chunk.decode()\n",
    "    except UnicodeDecodeError:\n",
    "        if bytes_read > max_window_size:\n",
    "            raise UnicodeError(f\"Unable to decode frame after reading {bytes_read:,} bytes\")\n",
    "        log.info(f\"Decoding error with {bytes_read:,} bytes, reading another chunk\")\n",
    "        return read_and_decode(reader, chunk_size, max_window_size, chunk, bytes_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb59ecf9-580a-40cd-924d-c6800e557fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_lines_zst(file_name):\n",
    "    with open(file_name, 'rb') as file_handle:\n",
    "        buffer = ''\n",
    "        reader = zstandard.ZstdDecompressor(max_window_size=2**31).stream_reader(file_handle)\n",
    "        while True:\n",
    "            chunk = read_and_decode(reader, 2**27, (2**29) * 2)\n",
    "\n",
    "            if not chunk:\n",
    "                break\n",
    "            lines = (buffer + chunk).split(\"\\n\")\n",
    "\n",
    "            for line in lines[:-1]:\n",
    "                yield line.strip(), file_handle.tell()\n",
    "\n",
    "            buffer = lines[-1]\n",
    "\n",
    "        reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f15e898-61a7-43ef-93bb-1e867ec365ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 12:16:57,835 - INFO: Output format set to txt\n",
      "2023-08-21 12:16:59,138 - INFO: 2018-07-17 02:59:31 : 100,000 : 0 : 0 : 29,229,725:24%\n",
      "2023-08-21 12:17:00,521 - INFO: 2019-07-28 19:04:25 : 200,000 : 0 : 0 : 41,157,550:33%\n",
      "2023-08-21 12:17:02,164 - INFO: 2020-04-29 13:15:36 : 300,000 : 0 : 0 : 62,391,700:51%\n",
      "2023-08-21 12:17:03,916 - INFO: 2021-01-19 02:47:12 : 400,000 : 0 : 0 : 82,184,025:67%\n",
      "2023-08-21 12:17:06,147 - INFO: 2021-11-25 05:58:09 : 500,000 : 0 : 0 : 101,845,275:83%\n",
      "2023-08-21 12:17:08,368 - INFO: 2022-10-28 15:32:54 : 600,000 : 0 : 0 : 121,637,600:99%\n",
      "2023-08-21 12:17:08,754 - INFO: No matching lines found.\n",
      "2023-08-21 12:17:08,755 - INFO: Complete : 620,963 : 0 : 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # if desired_field1 and desired_field2 and desired_field3 and desired_field4:\n",
    "    #     log.info(\"Single field output mode, changing output file format to txt\")\n",
    "    #     output_format = \"txt\"\n",
    "    output_path = f\"{output_file}.{output_format}\"\n",
    "\n",
    "    writer = None\n",
    "    if output_format == \"zst\":\n",
    "        log.info(\"Output format set to zst\")\n",
    "        handle = zstandard.ZstdCompressor().stream_writer(open(output_path, 'wb'))\n",
    "    elif output_format == \"txt\":\n",
    "        log.info(\"Output format set to txt\")\n",
    "        handle = open(output_path, 'w', encoding='UTF-8')\n",
    "    elif output_format == \"csv\":\n",
    "        log.info(\"Output format set to csv\")\n",
    "        handle = open(output_path, 'w', encoding='UTF-8', newline='')\n",
    "        writer = csv.writer(handle)\n",
    "    else:\n",
    "        log.error(f\"Unsupported output format {output_format}\")\n",
    "        sys.exit()\n",
    "\n",
    "    if values_file:\n",
    "        values = []\n",
    "        with open(values_file, 'r') as values_handle:\n",
    "            for value in values_handle:\n",
    "                values.append(value.strip().lower())\n",
    "        log.info(f\"Loaded {len(values)} from values file\")\n",
    "    else:\n",
    "        values = [value.lower() for value in values]  # convert to lowercase\n",
    "        \n",
    "    file_size = os.stat(input_file).st_size\n",
    "    file_bytes_processed = 0\n",
    "    created = None\n",
    "    matched_lines = 0\n",
    "    bad_lines = 0\n",
    "    total_lines = 0\n",
    "    for line, file_bytes_processed in read_lines_zst(input_file):\n",
    "        total_lines += 1\n",
    "        if total_lines % 100000 == 0:\n",
    "            log.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {total_lines:,} : {matched_lines:,} : {bad_lines:,} : {file_bytes_processed:,}:{(file_bytes_processed / file_size) * 100:.0f}%\")\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            created = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
    "\n",
    "            if created < from_date:\n",
    "                continue\n",
    "            if created > to_date:\n",
    "                continue\n",
    "\n",
    "            field_value = obj[field].lower()\n",
    "            matched = False\n",
    "            if not values:\n",
    "                if output_format == \"zst\":\n",
    "                    write_line_zst(handle, line)\n",
    "                elif output_format == \"csv\":\n",
    "                    write_line_csv(writer, obj, is_submission)\n",
    "                elif output_format == \"txt\":\n",
    "                    if desired_field1 and desired_field2 and desired_field3 and desired_field4:\n",
    "                        write_line_single(handle, obj, desired_field1)\n",
    "                        write_line_single(handle, obj, desired_field2)\n",
    "                        write_line_single(handle, obj, desired_field3)\n",
    "                        write_line_single(handle, obj, desired_field4)\n",
    "                    else:\n",
    "                        write_line_json(handle, obj)\n",
    "            for value in values:\n",
    "                if exact_match:\n",
    "                    if value == field_value:\n",
    "                        matched = True\n",
    "                        break\n",
    "                else:\n",
    "                    if value in field_value:\n",
    "                        matched = True\n",
    "                        break\n",
    "                if matched:\n",
    "                    matched_lines += 1\n",
    "                    if output_format == \"zst\":\n",
    "                        write_line_zst(handle, line)\n",
    "                    elif output_format == \"csv\":\n",
    "                        write_line_csv(writer, obj, is_submission)\n",
    "                    elif output_format == \"txt\":\n",
    "                        if desired_field1 and desired_field2 and desired_field3 and desired_field4:\n",
    "                            write_line_single(handle, obj, desired_field1)\n",
    "                            write_line_single(handle, obj, desired_field2)\n",
    "                            write_line_single(handle, obj, desired_field3)\n",
    "                            write_line_single(handle, obj, desired_field4)\n",
    "                        else:\n",
    "                            write_line_json(handle, obj)\n",
    "        except (KeyError, json.JSONDecodeError) as err:\n",
    "            bad_lines += 1\n",
    "            \n",
    "    if matched_lines == 0:\n",
    "        log.info(\"No matching lines found.\")\n",
    "        if output_format == \"txt\":\n",
    "            handle.write(\"No matching lines found.\\n\")\n",
    "\n",
    "    handle.close()\n",
    "    log.info(f\"Complete : {total_lines:,} : {matched_lines:,} : {bad_lines:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd99cef-929b-4f9c-a41b-97a888f56e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
